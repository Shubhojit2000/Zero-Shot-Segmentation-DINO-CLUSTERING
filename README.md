# Zero-Shot Semantic Segmentation with DINO and Clustering

This repository presents a lightweight, **zero-shot segmentation pipeline** using a pretrained DINO Vision Transformer and unsupervised clustering. The approach requires no labeled data or additional training, making it ideal for rapid prototyping on new domains or classes.

---

## ğŸ“Œ Overview

This method segments objects in images **without any supervision** using:

- A pretrained DINO ViT-S/8 model to extract dense patch embeddings
- Principal Component Analysis (PCA) to reduce feature dimensionality
- K-Means clustering to group semantically similar pixels
- Upsampling to generate full-resolution segmentation masks

---

## ğŸ§  Key Features

- ğŸš« **No training required** â€“ everything is zero-shot
- ğŸ¯ Based on semantically rich **DINO embeddings**
- âš¡ Fast execution on CPU or GPU
- ğŸ–¼ï¸ Saves both raw segmentation masks and visualization comparisons

---

## ğŸ–¥ï¸ File Structure

- main.py # Main script
-  *.png # Input images (in current directory)
-   visualizations/ # Side-by-side original+mask
-   README.md # This file

---

## ğŸš€ How to Run

**Install dependencies**:

```bash
pip install torch torchvision matplotlib scikit-learn pillow
```

**Run the script**

```bash
python main.py
